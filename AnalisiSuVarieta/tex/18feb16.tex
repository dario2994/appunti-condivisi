\chapter{Forme differenziali} %TODO: sarà un capitolo

\begin{definition} \index{forma!differenziale}
	Le \emph{forme differenziali} sono campi tensoriali di tipo $\Tau_k^0(M)$ totalmente antisimmetrici
\end{definition}

Hanno applicazioni per esempio in geometria perché possono dare informazioni sulla topologia delle varietà.

\section{Algebre esterne}

\begin{definition}
 
Dati $V,W$ spazi vettoriali (finito dimensionali), le \emph{mappe antisimmetriche} in $T^0_k(V,W)$ sono quelle per cui vale $t(\seqb{e}{k}{,}) = (\sgn \sigma) t(e_{\sigma(1)},\ldots, e_{\sigma(k)})$ per ogni $\seqb{e}{k}{,} \in V$ e per ogni $\sigma\in S_k$.
Si indicano con $\Lambda^k(V,W)$ (per brevità indicheremo anche $\Lambda^k(V,\R) = \Lambda^k(V)$) e vengono dette $k$-forme esterne.

\end{definition}

Dato $t\in T^0_k(V,W)$ è possibile ottenere un elemento di $\Lambda^k(V,W)$ tramite antisimmetrizzazione. 
\begin{example}
	Se $k=2$, dato $t\in T^0_2(V,W)$, possiamo definire il suo antisimmetrizzato come $\underline{A}t(e_1,e_2) = \frac 12 [t(e_1,e_2) - t(e_2,e_1)]$.
\end{example}

\begin{definition}
	La mappa alternante $\antisimm:T^0_k(V,W) \to \Lambda^k(V,W)$ è definita da
	\begin{equation*}
		\antisimm t(\seqb{e}{k}{,}) = \frac 1 {k!} \sum_{\sigma \in S_k} (\sgn \sigma) t(e_{\sigma(1)},\ldots, e_{\sigma(k)}) \punto
	\end{equation*}
\end{definition}

\begin{proposition}
	La mappa $\antisimm$ è lineare e suriettiva su $\Lambda^k(V,W)$, $\antisimm\restrict{\Lambda^k(V,W)} = \id\restrict{\Lambda^k(V,W)}$ e $\antisimm \circ \antisimm = \antisimm$.
\end{proposition}
\begin{proof}
	La linearità è ovvia. Sia $t\in\Lambda^k(V,W)$, allora
	\begin{align*}
		\antisimm t(\seqb{e}{k}{,}) &= \frac 1 {k!} \sum_{\sigma \in S_k} (\sgn \sigma) t(e_{\sigma(1)},\ldots, e_{\sigma(k)}) =\\
		& = \frac 1 {k!} \sum_{\sigma \in S_k} (\sgn \sigma)^2 t(\seqb{e}{k}{,}) = t (\seqb{e}{k}{,}) \virgola
	\end{align*}
	dove abbiamo usato che $t\in\Lambda^k$ e $\mathrm{card} S_k = k!$.
\end{proof}

\begin{remark}
	$\antisimm^2=\antisimm$ e quindi $\norm\antisimm \le \norm\antisimm^2$, da cui $\norm\antisimm \ge 1 $.
	D'altronde, le permutazioni preservano la norma, quindi $\norm{\antisimm t} \le \norm{t}$ e perciò $\norm \antisimm \le 1$.
	E unendo le due disuguaglianze otteniamo proprio $\norm\antisimm = 1$.
\end{remark}

Si chiamano algebre esterne perché si può fare un prodotto esterno.

\begin{definition}
	Se $\alpha \in T^0_k(V)$ e $\beta \in T^0_l(V)$. Il \emph{prodotto wedge} $\alpha \wedge \beta \in \Lambda^{k+l}(V)$ è definito da
	\begin{equation*}
		\alpha\wedge \beta \coloneqq \frac {(k+l)!}{k!\ l!} \antisimm(\alpha\otimes \beta)\punto
	\end{equation*}
\end{definition}

\begin{example}
	Se $\alpha,\beta\in\Lambda^1(V) \cong T^0_1(V)$, allora $(\alpha\wedge \beta)(e_1,e_2) = \alpha(e_1)\beta(e_2) - \alpha(e_2)\beta(e_1)$.
\end{example}

\begin{exercise}
	Un \emph{mescolamento} di tipo $(k,l)$ è una permutazione $\sigma \in S_{k+l}$ tale che $\sigma(1) < \ldots < \sigma(k)$ e $\sigma(k+1) <\ldots < \sigma(k+l)$.
	Se $\alpha\in\Lambda^k(V)$ e $\beta\in\Lambda^l(V)$, allora $(\alpha\wedge\beta)(\seqb{e}{k+l}{,}) = \sum_{\sigma \in mescolamenti(k,l)} \alpha(e_{\sigma(1)},\ldots,e_{\sigma(k)}) \beta(e_{\sigma(k+1)},\ldots,e_{\sigma(k+l)})$.
\end{exercise}

\begin{proposition}
	Se $\alpha \in T^0_k(V)$, $\beta \in T^0_l(V)$ e $\gamma \in T^0_m(V)$, si ha
	\begin{enumerate}
		\item $\alpha\wedge\beta = (\antisimm \alpha) \wedge \beta = \alpha\wedge (\antisimm \beta)$;
		\item $\wedge$ è bilineare;
		\item $\alpha\wedge \beta = (-1)^{kl} \beta \wedge \alpha$;
		\item $\alpha\wedge(\beta\wedge \gamma) = (\alpha\wedge\beta)\wedge\gamma = \frac{(k+l+m)!}{k!\ l!\ m!}\antisimm(\alpha\otimes\beta\otimes\gamma)$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	1)
	Siano $\sigma \in S_k$ e $t\in T^0_k(V)$. Definiamo $\sigma t(\seqb{e}{k}{,}) = t(e_{\sigma(1)}, \ldots, e_{\sigma(k)})$.
	Claim: $\antisimm (\sigma t) = (\sgn \sigma) \antisimm t$.
	Dimostriamolo:
	\begin{align*}
		\antisimm (\sigma t) &= \frac 1{k!} \sum_{\rho \in S_k} (\sgn \rho) t(e_{\rho\sigma (1)},\ldots,e_{\rho\sigma(k)}) =\\
		&= \frac 1{k!} \sum_{\tau\in S_k} (\sgn\tau)(\sgn\sigma) t(e_{\tau(1)}, \ldots, e_{\tau(k)}) = (\sgn\sigma) (\antisimm t)(\seqb{e}{k}{,})\punto
	\end{align*}
	
	Quindi ora, con la nuova definizione, abbiamo
	\begin{equation*}
		\antisimm t = \frac 1{k!} \sum_{\sigma\in S_k} (\sgn\sigma) \sigma t \punto
	\end{equation*}

	\begin{equation*}
		\antisimm(\antisimm \alpha \otimes \beta) = \antisimm(\frac 1{k!} \sum_{\tau\in S_k} (\sgn\tau) (\tau\alpha \otimes \beta)) =
		\frac 1{k!} \sum_{\tau\in S_k}(\sgn\tau) \antisimm(\tau\alpha\otimes \beta)\punto
	\end{equation*}
	Sia $\tau'\in S_{k+l}$ tale che
	\begin{equation*}
		\tau'(1,\ldots,k,k+1,\ldots,k+l) = (\tau(1),\ldots,\tau(k),k+1,\ldots,k+l)
	\end{equation*}
	da cui $\sgn\tau'=\sgn\tau$.
	Perciò la cosa sopra diventa
	\begin{equation*}
		\frac 1{k!} \sum_{\tau\in S_k} (\sgn\tau')\antisimm\tau'(\alpha\otimes \beta)\punto
	\end{equation*}
	Quindi $\antisimm(\antisimm\alpha\otimes \beta) = \frac 1{k!} \sum_{\tau\in S_k} (\sgn\tau')(\sgn\tau')\antisimm(\alpha\otimes \beta)=\frac 1{k!} \sum_{\tau\in S_k} \antisimm(\alpha\otimes \beta)$

	Perciò $\antisimm(\antisimm\alpha\otimes \beta) = \antisimm(\alpha\otimes\beta)$ e quindi $(\antisimm\alpha)\wedge\beta = \alpha\wedge\beta$.
	
	La 2 è ovvia.
	
	3) 
	Sia $\sigma_0\in S_{k+l}$ data da $\sigma(1,\ldots,k+l) = (k+1,\ldots,k+l,1,\ldots,k)$. Allora $(\alpha\otimes \beta)(\seqb{e}{k+l}{,}) = (\beta\otimes \alpha)(e_{\sigma_0(1)},\ldots,e_{\sigma_0(k+l)})$.
	Allora per il claim $\antisimm(\alpha\otimes\beta) = (\sgn\sigma_0) \antisimm(\beta\otimes\alpha)=(-1)^{kl} \beta \wedge \alpha$.

	4)
	$\alpha\wedge(\beta\wedge\gamma) = \frac{(k+l+m)!}{k!(l+m)!}\antisimm(\alpha\otimes(\beta\wedge\gamma)) = \frac{(k+l+m)!}{k!(l+m)!} \frac{(l+m)!}{l!m!} \antisimm(\alpha\otimes\antisimm(\beta\otimes\gamma))= \frac{(k+l+m)!}{k!l!m!}\antisimm(\alpha\otimes\beta\otimes\gamma)$
	
	Idem per la seconda.

\end{proof}




