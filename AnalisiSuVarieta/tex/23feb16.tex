\chapter{23 febbraio 2016}

\begin{remark}
	Dati $\seqa{\alpha}{k}{,}\in\Lambda^1(V)$, allora
	\begin{equation*}
		(\seqa{\alpha}{k}{\wedge})(\seqb{e}{k}{,}) = \sum_{\sigma\in S_k} \sgn(\sigma) \alpha^1(e_{\sigma(1)}) \ldots \alpha^k(e_{\sigma(k)}) = \det[\alpha^i(e_j)]
	\end{equation*}
	E dalla 4 $\seqa{\gamma}{k}{\wedge} = \frac{(\seqb{d}{k}{+})!}{d_1!\ldots d_k!}\antisimm (\seqa{\gamma}{k}{\otimes})$.
	
	Applicando a 1-forme $\seqb{\alpha}{k}{\wedge} = k! \antisimm(\seqb{\alpha}{k}{\otimes})$.
	Se $\seqb en,$ è una base di $V$ e se $\{\seqa en,\}$ è una base duale, allora $\{\seqa ek\wedge \}\cdot (\seqb en,) = 1$.

\end{remark}

Prodotto wedge in componenti

Sia $\seqb en,$ una base di $V$. Le componenti $t_{\seqb ik{}}$ di $t\in T^0_k(V)$ sono date da $t(e_{i_1},\ldots,e_{i_k})$.
Se $t\in\Lambda^k(V)$, c'è antisimmetria e $(\antisimm t) = \frac 1{k!} \sum_{\sigma\in S_k} \sgn(\sigma) t_{\sigma(i_1)\ldots\sigma(i_k)}$. $\antisimm$ antisimmetrizza le componenti.

Se $\alpha\in\Lambda^k(V)$ e $\beta\in\Lambda^l(V)$, allora
\begin{equation*}
	(\alpha\wedge\beta)_{\seqb{i}{k+l}{}} = \sum_{\sigma\in(k,l) mescolamenti} \sgn(\sigma) \alpha_{\sigma(i_1)\ldots\sigma(i_k)} \beta_{\sigma(i_{k+1})\ldots\sigma(i_{k+l})}
\end{equation*}

\begin{definition}
	Dato $V$ spazio vettoriale $\Lambda(V)$, somma diretta dei $\Lambda^k(V)$, è detta \emph{algebra esterna} di $V$.
\end{definition}

\begin{proposition}
	Se $V$ ha dimensione $n$, $\Lambda^k(V)=0$ per $k>n$ e ha dimensione $\binom nk$ per $k=1,\ldots,n$. Quindi $\Lambda(V)$ ha dimensione $2^n$.
	
	Se $\seqb en,$ è una base di $V$, l'insieme $\{ e^{i_1}\wedge\ldots\wedge e^{i_k} \suchthat 1\le i_i< \ldots < i_k\le n\}$ è una base di $\Lambda^k(V)$.
\end{proposition}

\begin{corollary}
	Sia $\theta\in\Lambda^1(V)$ e $\alpha\in\Lambda^k(V)$. Allora $\theta\wedge\alpha=0$ se e solo se esiste $\beta\in\Lambda^{k-1}(V)$ tale che $\alpha = \theta \wedge \beta$.
\end{corollary}
\begin{proof}
	Si usa il fatto che, se $\theta\in\Lambda^1(V)$, allora $\theta\wedge\theta=0$ \footnote{Questo in generale è falso per $k$ pari: sia per esempio $\omega=e^1\wedge e^2+e^3\wedge e^4$ in $\R^4$, allora $\omega\wedge\omega = 2e^1\wedge e^2 \wedge e^3\wedge e^4 \not=0$} (per la 3).
	Quindi se $\alpha=\theta\wedge\beta$, per la 4 $\theta\wedge\alpha=0$.
	
	Viceversa, sia $\theta\wedge\alpha=0$. Sia $\seqb en,$ base di $V$ tale che $e^k=\theta$. Se $\alpha=\sum_{i_1<\ldots<i_k} \alpha_{\seqb ik{}} e^{i_1}\wedge\ldots\wedge e^{i_k}$, la condizione $\theta\wedge\alpha=0$ implica che i coefficienti in cui $k$ non compare sono nulli. Quindi $\alpha$ si fattorizza con $e^k$ e una $k-1$ forma $\beta$.
\end{proof}

\begin{example}
	\begin{enumerate}
		\item Sia $V = \R^2$, $\{e_1,e_2\}$ la base canonica e $\{e^1,e^2\}$ la base duale. Ogni $\omega\in\Lambda^1(\R^2)$ si scrive come $\omega = \omega_1e^1+\omega_2e^2$ e ogni $\omega\in\Lambda^2(\R^2)$ si scrive come $\omega = \omega_{12}\ e^1\wedge e^2$. 
		
		\item In $\R^3$, $\Lambda^1$ e $\Lambda^2$ hanno la stessa dimensione e dunque sono isomorfi. Data $\{e_i\}_{i=1,2,3}$ base canonica e $\{e^i\}$ base duale un isomorfismo è il seguente: $e^1\mapsto e^2\wedge e^3$ e cicliche.
		Questo è detto \emph{operatore Hodge star} che indichiamo con $*$. L'isomorfismo standard di $\R^3$ con $\Lambda^1(\R^3)$ è l'operatore $\flat$: $^\flat(e_i) = e^i$.
		
		Allora $*\circ \flat:\R^3\to \Lambda^2(\R)$ soddisfa
		\begin{equation*}
			(*\circ \flat) (e\times f) = {^\flat e} \times {^\flat f}\punto 
		\end{equation*}
		Se $\alpha = \alpha_ie^i$ e $\beta = \beta_j e^j$, allora
		\begin{equation*}
			\alpha\wedge\beta = (\alpha_2\beta_3 - \beta_2\alpha_3)e^2\wedge e^3 + (\alpha_3\beta_1 - \alpha_1\beta_3)e^3\wedge e^1 + (\alpha_1\beta_2 - \alpha_2\beta_1) e^1\wedge e^2 \punto
		\end{equation*}
	\end{enumerate}
\end{example}

\begin{exercise}
	Siano $\seqb vk, \in V$ linearmente indipendenti. Mostrare che $\alpha(\seqb vk,) = 0$ qualsiasi $\alpha\in\Lambda^k(V)$. 
\end{exercise}


\section{Determinanti e volumi}

Il determinante di una matrice è multilineare e antisimmetrico su righe e colonne di una matrice.
Se $\seqb xn, \in\R^n$ con componenti $x_i^j$, allora il determinante di $(x_i^j)$ è il volume del parallelepipedo generato da $\seqb xn,$.
Possiamo indicare
\begin{equation*}
	\det[\seqb xn,] = \sum_{\sigma\in S_n} \sgn(\sigma) x_{\sigma(1)}^1\ldots x_{\sigma(n)}^n \punto
\end{equation*}
Se $\varphi:\R^n\to\R^n$ è lineare $\det\varphi = \frac{\text{volume del parallelepipedo generato da $\varphi(e_1),\ldots,\varphi(e_n)$}}{\text{volume del cubo unitario}}$.

\begin{proposition}
	Siano $\varphi\in\Lin(V,W)$ e $\psi\in\Lin(W,Z)$. Allora $\varphi^* : T^0_k(W) \to T^0_k(V)$ è lineare e 
	\begin{enumerate}
		\item $\varphi^*(\Lambda^k(W)) \subseteq \Lambda^k(V)$;
		\item $(\psi\circ\varphi)^* = \varphi^* \circ \psi^*$;
		\item $\id^* = \id$;
		\item se $\varphi\in \mathrm{inv}(V,W)$, $\varphi^*\in \mathrm{inv}(T^0_k(W), T^0_k(V))$ e $(\varphi^*)^{-1} = (\varphi^{-1})^* = \varphi_*$.
		Se anche $\psi\in\mathrm{inv}(W,Z)$, allora $(\psi\circ\varphi)_* = \psi_*\circ \varphi_*$;
		\item se $\alpha\in\Lambda^k(V)$, $\beta\in\Lambda^l(W)$, allora $\varphi^*(\alpha\wedge\beta) = (\varphi^*\alpha) \wedge (\varphi^*\beta)$.
	\end{enumerate}
\end{proposition}

Ricordiamo che $\dim(\Lambda^n(V)) = 1$, dove $\dim(V)=n$.
\begin{definition}
	Se $V$ ha dimensione $n$ e $\varphi\in\Lin(V,V)$, $\det(\varphi)$ è definito come l'unica costante tale che $\varphi^*\omega = \det(\varphi) \omega$, qualsiasi $\omega\in\Lambda^n(V)$.
\end{definition}

\begin{proposition}
	Sia $\seqb en,$ una base di $B$ con base duale $\seqa en,$. Sia $\varphi(e_i) = A_i^je_j$.
	Dalla dimostrazione dell'associatività di $\Lambda$
	\begin{align*}
		\varphi^*(\seqa en\wedge) (\seqb en,) &= (\seqa en\wedge)(\varphi(e_1),\ldots, \varphi(e_n)) =\\
		&=n!\ \antisimm (\seqa en\otimes)(\varphi(e_1),\ldots,\varphi(e_n)) = \det A
		\punto
	\end{align*}
	(multilineare e normalizzata a 1 sulla mappa identica)
\end{proposition}

\begin{proposition}
	Siano $\varphi,\psi \in\Lin(V,V)$. Allora
	\begin{enumerate}
		\item $\det(\varphi\circ\psi) = \det \varphi \cdot \det \psi$;
		\item $\det \id = 1$;
		\item $\varphi$ è un isomorfismo se e solo se $\det\varphi\not=0$. In tal caso $\det\varphi^{-1} = (\det \varphi)^{-1}$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	L'unica non ovvia è la freccia $<=$ della 3.
	
	Basta dimostrare che se $\varphi$ non è un isomorfismo, allora $\det\varphi = 0$.
	Se $\varphi$ non è un isomorfismo, esiste $e=e_1\in\ker\varphi$. Completo $e_1$ a una base $\{\seqb en,\}$ di $V$. Data $\omega\in\Lambda^n(V)$, allora
	\begin{equation*}
		(\varphi^*\omega)(\seqb en,) = \omega(\varphi(e_1),\ldots,\varphi(e_n)) = \omega(0,\varphi(e_2),\ldots,\varphi(e_n)) = 0
	\end{equation*}
	perché $\omega$ è multilineare. Perciò $\det\varphi = 0$.
\end{proof}

\begin{definition} \index{orientazione}
	Gli elementi di $\Lambda^n(V)$ sono detti \emph{elementi di volume}. Se $\omega_1,\omega_2$ sono elementi di volume diciamo che $\omega_1\sim \omega_2$ se esiste $c>0$ tale che $\omega_1 = c\omega_2$. Una classe di equivalenza di elementi di volume è detta un'\emph{orientazione} su $V$.
	
	Uno \emph{spazio orientato} $(V, [\omega])$ è uno spazio vettoriale con un'orientazione $[\omega]$. La classe $[-\omega]$ è detta \emph{orientazione inversa}.
	
	Una base $\{\seqb en,\}$ di $(V,[\omega])$ orientato è detta essere orientata positivamente se $\omega(\seqb en,)>0$ \footnote{Ovviamente tale definizione è indipendente dalla scelta di un elemento di $[\omega]$.}.
\end{definition}

\begin{proposition}
	Sia $g\in T^0_2(V)$ simmetrico e definito positivo. Allora esiste una base $\{\seqb en,\}$ di $V$ (con base duale $\{\seqa en,\}$) tale che $g = \sum_{i=1}^n e^i\otimes e^i$. Questa base è detta \emph{ortogonale} rispetto a $g$.
\end{proposition}
\begin{proof}
	La dimostrazione è analoga al caso di $\R^n$ utilizzando un processo di ortogonalizzazione di Gram-Schmidt.
	
	Dalla polarizzata $g(e,f) = \frac 14 [g(e+f,e+f) + g(e-f,e-f)]$.
	Sia $e_1$ tale che $g(e_1,e_1) = 1$. Sia $V_1 = \spanrm \{e_1\}$ e sia $V_2 = \{e \suchthat g(e,e_1) = 0\}$.
	Visto che $g$ è definita positiva, $V_1\cap V_2= \{0\}$. Dato $z\in V$, allora $z = g(e_1,z)e_1 + (z-g(e_1,z)e_1)$, dove il secondo termine appartiene a $V_2$. Quindi $V = V_1\oplus V_2$.
	Scegliamo quindi $e_2\in V_2$ tale che $g(e_2,e_2)=1$ e così via fino a completare la base.
\end{proof}


\begin{proposition}
	Sia $V$ uno spazio vettoriale $n$ dimensionale e sia $g\in T^0_2(V)$ simmetrico, definito positivo. Allora, se $[\omega]$ è un'orientazione in $V$, esiste un unico elemento di volume $\mu(g) \in [\omega]$ (detto $g$-volume) tale che $\mu(g)(\seqb en,) = 1$ per ogni base ortonormale e orientata $\seqb en,$ di $V$.
	Se poi $\seqa en,$ è la base duale, allora $\mu(g) = \seqa en\wedge$.
	
	In generale, se $\seqb fn,$ è una base orientata positivamente e se $f^i$ è la base duale, allora
	\begin{equation*}
		\mu(g) = \abs{ \det[g(f_i,f_j)] }^{\frac 12}\ \seqa fn\wedge \punto
	\end{equation*}
\end{proposition}
\begin{proof}
	Per la proposizione precedente $g(f_i,f_j) = \sum_p e^p\otimes e^p (f_i,f_j)$. Esiste quindi $\varphi \in \mathrm{inv}(V,V)$ tale che $f_i = \varphi(e_i) = A_i^j(e_j)$.
	Perciò $g(f_i,f_j) = \sum_p e^p\otimes e^p (A_i^k e_k, A_i^le_l) = \sum_p \delta_k^p \delta_l^p A_i^k A_j^l = \sum_pA_i^pA_j^p$.
	Quindi $\det[g(f_i,f_j)] = (\det\varphi)^2\det[g(e_i,e_j)] = (\det\varphi)^2$.
	Se $\{\seqb en,\}$ è orientata positivamente e $g$-ortogonale $\mu(\seqb en,) = 1$ determina $\mu$ univocamente.
	
	Se $\seqb fn,$ è un'altra base orientata positivamente e $g$-ortogonale e sia $\varphi$ come sopra. Allora $\abs{\det\varphi} = 1$. Ma $0<\mu(\seqb fn,) = (\varphi^*\mu)(\seqb en,)\det\varphi$, quindi $\det\varphi=1$.
	
	La 3 implica la 2.
	
	Per la formula si usa $\mu(\seqb fn,) = \det\varphi = \abs{ \det[g(f_i,f_j)] }^\frac 12$.
\end{proof}































































